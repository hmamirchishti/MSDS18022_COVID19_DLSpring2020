{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSDS18022_05",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "iMDaRbg0SaBp",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 5: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "oJPHi-gpSaBq",
        "colab_type": "text"
      },
      "source": [
        "##Task-1\n",
        "### Fine-tuning resnet18 on X-Ray Chest data\n",
        "In this tutorial we will learn how to fine-tune a pre-trained network on a new dataset.\n",
        "We will perform the following steps:\n",
        "1. Load and normalizing the X-Ray dataset\n",
        "2. Load pre-trained ResNet18 \n",
        "3. Remove top layers (fully connected layers)\n",
        "4. Freeze the network\n",
        "4. Add new layers (classifier)\n",
        "5. Train the network\n",
        "6. Plot Loss & Accuracies with Epochs\n",
        "7. Confusion Matrix\n",
        "8. F1 Score\n",
        "9. Test Final Accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZX2vEeFvSaBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from google.colab import drive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "g7FS6lfASaBv",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset usign torchvision image loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "afyYRGAkSaBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "# drive.mount(\"./gdrive\")\n",
        "# data_dir = '/content/drive/My Drive/MSDS/Semester 4/DL/Homeworks/Homework 5/Assignment 5 Dataset'\n",
        "\n",
        "!unzip \"/content/drive/My Drive/Assignment 5 Dataset.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LW4HhHTgSaBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"Assignment 5 Dataset\"\n",
        "#Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "#pass transform here-in\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/validation', transform=test_transforms)\n",
        "\n",
        "#data loaders\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=1500, shuffle=True)\n",
        "\n",
        "print(\"Classes: \")\n",
        "class_names = train_data.classes\n",
        "print(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jHtOfltYSaB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "def show_databatch(inputs, classes):\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(trainloader))\n",
        "show_databatch(inputs, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Wxsbfd_VSaB7",
        "colab_type": "text"
      },
      "source": [
        "## ResNet-18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "H63bcr4DSaB8",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s-fS-wW3SaB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the pretrained model from pytorch\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "print(resnet18)\n",
        "# print('Output Layer of resnet18 : ', resnet18.classifier[6].out_features) # 1000 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nnLUlRhVSaCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(resnet18.fc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "s92eyaDFSaCF",
        "colab_type": "text"
      },
      "source": [
        "### Removing Last Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UzWU0Gc9SaCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = resnet18.fc.in_features # 0 means input we are receiving from VGG Conv features\n",
        "# putting array value 0 instead of -1 (which is used to neglect last layer) to add new layers\n",
        "features = list(resnet18.fc.children())[:0] # Remove all FC layer\n",
        "print(num_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "x95-leMJSaCJ",
        "colab_type": "text"
      },
      "source": [
        "### Freezing the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ExdWZe14SaCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze training for all layers\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "evRWRFdcSaCM",
        "colab_type": "text"
      },
      "source": [
        "### Adding New Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "brqcmTbiSaCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roll_number_neurons = 22*10+100\n",
        "features.extend([\n",
        "                 nn.Linear(num_features, roll_number_neurons)\n",
        "                 ,nn.ReLU(inplace=True)\n",
        "                 ,nn.Linear(roll_number_neurons, len(class_names))\n",
        "                 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OV5sTZ54SaCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18.fc = nn.Sequential(*features)\n",
        "print(resnet18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "psxPGn-_SaCV",
        "colab_type": "text"
      },
      "source": [
        "### Loss fucntion and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "H5enn3VeSaCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OrunFuHjSaCY",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wXqIe3q2SaCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "since = time.time()\n",
        "#if you have gpu then you need to convert the network and data to cuda\n",
        "#the easiest way is to first check for device and then convert network and data to device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "resnet18.to(device)\n",
        "\n",
        "# resnet18.train()\n",
        "loss_plot = []\n",
        "loss_plot_val = []\n",
        "accuracy_plot = []\n",
        "accuracy_plot_val=[]\n",
        "\n",
        "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    pbar = tqdm(enumerate(trainloader))\n",
        "    for i, data in pbar:\n",
        "        # if i==4:\n",
        "        #   break\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
        "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "        # This is convenient while training RNNs. \n",
        "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet18(inputs)               #----> forward pass\n",
        "        _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "        loss = criterion(outputs, labels)   #----> compute loss\n",
        "        \n",
        "        loss.backward()                     #----> backward pass\n",
        "        optimizer.step()                    #----> weights update\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        train_data_len = len(trainloader.dataset)\n",
        "        epoch_loss = running_loss / train_data_len\n",
        "        epoch_acc = running_corrects.double() / train_data_len\n",
        "        pbar.set_description(\n",
        "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tTraining Loss: {:.4f}  Training Acc: {:.4f}'.format(\n",
        "                epoch, i * len(inputs), len(trainloader.dataset),\n",
        "                100. * i / len(trainloader),\n",
        "                epoch_loss, epoch_acc))\n",
        "        # pbar.set_description(\n",
        "        #     'Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc)\n",
        "        #     )\n",
        "    \n",
        "    \n",
        "\n",
        "    loss_plot.append(epoch_loss)\n",
        "    \n",
        "    accuracy_plot.append(epoch_acc)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        running_loss_val = 0.0\n",
        "        running_corrects_val=0.0\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = resnet18(images)               #----> forward pass\n",
        "            _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "            loss_val = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss_val += loss_val.item()\n",
        "            running_corrects_val += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "        test_data_len = len(testloader.dataset)\n",
        "        epoch_loss = running_loss_val / test_data_len\n",
        "        epoch_acc = running_corrects_val.double() / test_data_len\n",
        "\n",
        "        loss_plot_val.append(epoch_loss)\n",
        "        accuracy_plot_val.append(epoch_acc)\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "        # print(loss)\n",
        "    torch.save(resnet18.state_dict(), 'resnet18_FC_Only.pth')\n",
        "\n",
        "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "oKFL_vUDSaCb",
        "colab_type": "text"
      },
      "source": [
        "### Plot Loss & Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xGgz0WQpSaCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot,label=\"Training Accuracy\")\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot_val,label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),loss_plot,label=\"Training Loss\")\n",
        "plt.plot(range(1,Epochs+1),loss_plot_val,label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "6nrXJmx0SaCh",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix & Two Worse and Best Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8Tz5sMjvSaCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "number_of_classes = 2\n",
        "confusion_matrix = torch.zeros(number_of_classes, number_of_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        outputs = resnet18(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(label.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Zmp6CtvbSaCk",
        "colab_type": "text"
      },
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fn2WO1R3SaCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,(inputs,label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        # compute output\n",
        "        output = resnet18(inputs)\n",
        "        loss = criterion(output,label)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        # losses.update(loss.item(),input.size(0))\n",
        "        f1_batch = f1_score(label.cpu(),preds.cpu() > 0.15,average='macro')\n",
        "print('F1 Score: ',f1_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cn6JzF2xSaCn",
        "colab_type": "text"
      },
      "source": [
        "### Final Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gvbj-NIeSaCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader) # converted it to train because test batch is of 1500 (converted to increase speed)\n",
        "images, labels = dataiter.next()\n",
        "show_databatch(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CxcArfn1SaCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
        "outputs = resnet18(images)                               #--> forward pass\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
        "                              for j in range(len(images))))\n",
        "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
        "                              for j in range(len(images))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QpB0ocwCSaCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet18(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Final Accuracy of the network on the 1500 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMyq77IvnKpa",
        "colab_type": "text"
      },
      "source": [
        "### Best and Worse Performing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ujfBnsZJSaCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "best_performing_image1 = 0\n",
        "best_performing_image2 = 0\n",
        "best_performing_image1_label = \"\"\n",
        "best_performing_image2_label = \"\"\n",
        "\n",
        "worse_performing_image1 = 0\n",
        "worse_performing_image2 = 0\n",
        "worse_performing_image1_label = \"\"\n",
        "worse_performing_image2_label = \"\"\n",
        "\n",
        "maximum = 0\n",
        "minimum = -9999\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet18(images)\n",
        "        probabilities, predicted = torch.max(outputs.data,1)\n",
        "\n",
        "        T_Pred_Mask= probabilities[predicted==labels]\n",
        "        F_Pred_Mask= probabilities[predicted!=labels]\n",
        "\n",
        "        if any(T_Pred_Mask) == True:\n",
        "          temp_max = torch.argmax(probabilities[predicted==labels])\n",
        "          if maximum < temp_max:\n",
        "            maximum = temp_max\n",
        "            best_performing_image2 = best_performing_image1\n",
        "            best_performing_image2_label = best_performing_image1_label\n",
        "\n",
        "            best_performing_image1_label = labels[maximum]\n",
        "            best_performing_image1 = images[maximum]\n",
        "        \n",
        "        if any(F_Pred_Mask) == True:\n",
        "          temp_min = torch.argmin(probabilities[predicted!=labels])\n",
        "          if minimum > temp_min  :\n",
        "            minimum = temp_min\n",
        "            worse_performing_image2 = worse_performing_image1\n",
        "            worse_performing_image2_label = worse_performing_image1_label\n",
        "\n",
        "            worse_performing_image1_label = labels[minimum]\n",
        "            worse_performing_image1 = images[minimum]\n",
        "\n",
        "        # total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "print('True Positive or True Negative with High Probability')\n",
        "imshow(best_performing_image1.cpu(),best_performing_image1_label.cpu())\n",
        "imshow(best_performing_image2.cpu(),best_performing_image2_label.cpu())\n",
        "\n",
        "print('False Positive or False Negative with High Probability')\n",
        "imshow(worse_performing_image1.cpu(),worse_performing_image1_label.cpu())\n",
        "imshow(worse_performing_image2.cpu(),worse_performing_image2_label.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_Bc0QlgTSaCz",
        "colab_type": "text"
      },
      "source": [
        "## VGG-16\n",
        "### Fine-tuning vgg16 on X-Ray Chest data\n",
        "In this tutorial we will learn how to fine-tune a pre-trained network on a new dataset.\n",
        "We will perform the following steps:\n",
        "1. Load and normalizing the X-Ray dataset\n",
        "2. Load pre-trained Vgg16 \n",
        "3. Remove top layers (fully connected layers)\n",
        "4. Freeze the network\n",
        "4. Add new layers (classifier)\n",
        "5. Train the network\n",
        "6. Plot Loss & Accuracies with Epochs\n",
        "7. Confusion Matrix\n",
        "8. F1 Score\n",
        "9. Test Final Accuracy on test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1QbplARXSaCz",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zv966149SaC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the pretrained model from pytorch\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "print(vgg16)\n",
        "print('Output Layer of VGG16 : ', vgg16.classifier[6].out_features) # 1000 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QpLrOW4XSaC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vgg16.classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RH0jhS4RSaC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = vgg16.classifier[0].in_features # 0 means input we are receiving from VGG Conv features\n",
        "# putting array value 0 instead of -1 (which is used to neglect last layer) to add new layers\n",
        "features = list(vgg16.classifier.children())[:0] # Remove all FC layer\n",
        "print(num_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ViWD8UvGSaC9",
        "colab_type": "text"
      },
      "source": [
        "### Freezing the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NJVchQJQSaC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze training for all layers\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ktm8DThQSaDA",
        "colab_type": "text"
      },
      "source": [
        "### Adding New Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TTjQFmXKSaDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roll_number_neurons = 22*10+100\n",
        "features.extend([\n",
        "                 nn.Linear(num_features, roll_number_neurons)\n",
        "                 ,nn.ReLU(inplace=True)\n",
        "                 ,nn.Linear(roll_number_neurons, len(class_names))\n",
        "                 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ShEA5aw4SaDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16.classifier = nn.Sequential(*features)\n",
        "print(vgg16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "XBZLvuo8SaDF",
        "colab_type": "text"
      },
      "source": [
        "### Loss fucntion and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Pwr_1mGDSaDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epochs = 3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OzFwC-ISSaDJ",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qqsySRXSSaDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "since = time.time()\n",
        "#if you have gpu then you need to convert the network and data to cuda\n",
        "#the easiest way is to first check for device and then convert network and data to device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "vgg16.to(device)\n",
        "\n",
        "# vgg16.train()\n",
        "loss_plot = []\n",
        "loss_plot_val = []\n",
        "accuracy_plot = []\n",
        "accuracy_plot_val=[]\n",
        "\n",
        "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    epoch_loss=0.0\n",
        "    epoch_acc=0\n",
        "    pbar = tqdm(enumerate(trainloader))\n",
        "    for i, data in pbar:\n",
        "        # if i==20: #my code was failing due to CUDA memory, so doing this to train on subset\n",
        "        #   break\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
        "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "        # This is convenient while training RNNs. \n",
        "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = vgg16(inputs)               #----> forward pass\n",
        "        _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "        loss = criterion(outputs, labels)   #----> compute loss\n",
        "        \n",
        "        loss.backward()                     #----> backward pass\n",
        "        optimizer.step()                    #----> weights update\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        train_data_len = len(trainloader.dataset)\n",
        "        epoch_loss = running_loss / train_data_len\n",
        "        epoch_acc = running_corrects.double() / train_data_len\n",
        "        pbar.set_description(\n",
        "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tTraining Loss: {:.4f}  Training Acc: {:.4f}'.format(\n",
        "                epoch, i * len(inputs), len(trainloader.dataset),\n",
        "                100. * i / len(trainloader),\n",
        "                epoch_loss, epoch_acc))\n",
        "        # pbar.set_description(\n",
        "        #     'Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc)\n",
        "        #     )\n",
        "    \n",
        "    train_data_len = len(trainloader.dataset)\n",
        "    epoch_loss = running_loss / train_data_len\n",
        "    epoch_acc = running_corrects.double() / train_data_len\n",
        "\n",
        "    loss_plot.append(epoch_loss)\n",
        "    \n",
        "    accuracy_plot.append(epoch_acc)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        running_loss_val = 0.0\n",
        "        running_corrects_val=0.0\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = vgg16(images)               #----> forward pass\n",
        "            _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "            loss_val = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss_val += loss_val.item()\n",
        "            running_corrects_val += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "        test_data_len = len(testloader.dataset)\n",
        "        epoch_loss = running_loss_val / test_data_len\n",
        "        epoch_acc = running_corrects_val.double() / test_data_len\n",
        "\n",
        "        loss_plot_val.append(epoch_loss)\n",
        "        accuracy_plot_val.append(epoch_acc)\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "        # print(loss)\n",
        "    torch.save(vgg16.state_dict(), 'vgg16_FC_Only.pth')\n",
        "\n",
        "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "oj5Tg4FOSaDN",
        "colab_type": "text"
      },
      "source": [
        "### Plot Loss & Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AaJA2XaISaDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot,label=\"Training Accuracy\")\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot_val,label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),loss_plot,label=\"Training Loss\")\n",
        "plt.plot(range(1,Epochs+1),loss_plot_val,label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OTO07IJJSaDS",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix & Two Worse and Best Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mvzGWF6QSaDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "number_of_classes = 2\n",
        "confusion_matrix = torch.zeros(number_of_classes, number_of_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        outputs = vgg16(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(label.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7H5DULVVSaDW",
        "colab_type": "text"
      },
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "p0w4ux8BSaDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,(inputs,label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        # compute output\n",
        "        output = vgg16(inputs)\n",
        "        loss = criterion(output,label)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        # losses.update(loss.item(),input.size(0))\n",
        "        f1_batch = f1_score(label.cpu(),preds.cpu() > 0.15,average='macro')\n",
        "print('F1 Score: ',f1_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "zUU_prJhSaDa",
        "colab_type": "text"
      },
      "source": [
        "### Final Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WjCtnjPUSaDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader) # converted it to train because test batch is of 1500 (converted to increase speed)\n",
        "images, labels = dataiter.next()\n",
        "show_databatch(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qDAsU7V5SaDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
        "outputs = vgg16(images)                               #--> forward pass\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
        "                              for j in range(len(images))))\n",
        "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
        "                              for j in range(len(images))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s57Fpp-ISaDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = vgg16(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Final Accuracy of the network on the 1500 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7HMTi15nVwJ",
        "colab_type": "text"
      },
      "source": [
        "### Best and Worse Performing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NVTb72pySaDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "best_performing_image1 = 0\n",
        "best_performing_image2 = 0\n",
        "best_performing_image1_label = \"\"\n",
        "best_performing_image2_label = \"\"\n",
        "\n",
        "worse_performing_image1 = 0\n",
        "worse_performing_image2 = 0\n",
        "worse_performing_image1_label = \"\"\n",
        "worse_performing_image2_label = \"\"\n",
        "\n",
        "maximum = 0\n",
        "minimum = -9999\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet18(images)\n",
        "        probabilities, predicted = torch.max(outputs.data,1)\n",
        "\n",
        "        T_Pred_Mask= probabilities[predicted==labels]\n",
        "        F_Pred_Mask= probabilities[predicted!=labels]\n",
        "\n",
        "        if any(T_Pred_Mask) == True:\n",
        "          temp_max = torch.argmax(probabilities[predicted==labels])\n",
        "          if maximum < temp_max:\n",
        "            maximum = temp_max\n",
        "            best_performing_image2 = best_performing_image1\n",
        "            best_performing_image2_label = best_performing_image1_label\n",
        "\n",
        "            best_performing_image1_label = labels[maximum]\n",
        "            best_performing_image1 = images[maximum]\n",
        "        \n",
        "        if any(F_Pred_Mask) == True:\n",
        "          temp_min = torch.argmin(probabilities[predicted!=labels])\n",
        "          if minimum > temp_min  :\n",
        "            minimum = temp_min\n",
        "            worse_performing_image2 = worse_performing_image1\n",
        "            worse_performing_image2_label = worse_performing_image1_label\n",
        "\n",
        "            worse_performing_image1_label = labels[minimum]\n",
        "            worse_performing_image1 = images[minimum]\n",
        "\n",
        "        # total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "print('True Positive or True Negative with High Probability')\n",
        "imshow(best_performing_image1.cpu(),best_performing_image1_label.cpu())\n",
        "imshow(best_performing_image2.cpu(),best_performing_image2_label.cpu())\n",
        "\n",
        "print('False Positive or False Negative with High Probability')\n",
        "imshow(worse_performing_image1.cpu(),worse_performing_image1_label.cpu())\n",
        "imshow(worse_performing_image2.cpu(),worse_performing_image2_label.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gsdbV-52SaDs",
        "colab_type": "text"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYOsAHJWSgud",
        "colab_type": "text"
      },
      "source": [
        "## ResNet-18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "HE_Kivv_SaD1",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RFNa8KQrSaD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the pretrained model from pytorch\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "print(resnet18)\n",
        "# print('Output Layer of resnet18 : ', resnet18.classifier[6].out_features) # 1000 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gQInKzJ2SaD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(resnet18.fc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Xbl6YcJWSaD-",
        "colab_type": "text"
      },
      "source": [
        "### Removing Last Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TMYkt2TTSaEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = resnet18.fc.in_features # 0 means input we are receiving from VGG Conv features\n",
        "# putting array value 0 instead of -1 (which is used to neglect last layer) to add new layers\n",
        "features = list(resnet18.fc.children())[:0] # Remove all FC layer\n",
        "print(num_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vVJR8SenSaEE",
        "colab_type": "text"
      },
      "source": [
        "### Freezing the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lRDYxJSVSaEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze training for all layers\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for i in range(0,31): # Unfreezing all CNN Layer\n",
        "  resnet18.features[i].requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8SIpO2PSSaEJ",
        "colab_type": "text"
      },
      "source": [
        "### Adding New Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fBEe7AxRSaEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roll_number_neurons = 22*10+100\n",
        "features.extend([\n",
        "                 nn.Linear(num_features, roll_number_neurons)\n",
        "                 ,nn.ReLU(inplace=True)\n",
        "                 ,nn.Linear(roll_number_neurons, len(class_names))\n",
        "                 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OJ-oPWkMSaEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18.fc = nn.Sequential(*features)\n",
        "print(resnet18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7ypyKRsCSaES",
        "colab_type": "text"
      },
      "source": [
        "### Loss fucntion and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uFDrNmKqSaET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9LMjR36xSaEW",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NGQg_lGOSaEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "since = time.time()\n",
        "#if you have gpu then you need to convert the network and data to cuda\n",
        "#the easiest way is to first check for device and then convert network and data to device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "resnet18.to(device)\n",
        "\n",
        "# resnet18.train()\n",
        "loss_plot = []\n",
        "loss_plot_val = []\n",
        "accuracy_plot = []\n",
        "accuracy_plot_val=[]\n",
        "\n",
        "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    pbar = tqdm(enumerate(trainloader))\n",
        "    for i, data in pbar:\n",
        "        # if i==4:\n",
        "        #   break\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
        "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "        # This is convenient while training RNNs. \n",
        "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet18(inputs)               #----> forward pass\n",
        "        _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "        loss = criterion(outputs, labels)   #----> compute loss\n",
        "        \n",
        "        loss.backward()                     #----> backward pass\n",
        "        optimizer.step()                    #----> weights update\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        train_data_len = len(trainloader.dataset)\n",
        "        epoch_loss = running_loss / train_data_len\n",
        "        epoch_acc = running_corrects.double() / train_data_len\n",
        "\n",
        "        pbar.set_description(\n",
        "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tTraining Loss: {:.4f}  Training Acc: {:.4f}'.format(\n",
        "                epoch, i * len(inputs), len(trainloader.dataset),\n",
        "                100. * i / len(trainloader),\n",
        "                epoch_loss, epoch_acc))\n",
        "        # pbar.set_description(\n",
        "        #     'Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc)\n",
        "        #     )\n",
        "\n",
        "    loss_plot.append(epoch_loss)\n",
        "    \n",
        "    accuracy_plot.append(epoch_acc)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        running_loss_val = 0.0\n",
        "        running_corrects_val=0.0\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = resnet18(images)               #----> forward pass\n",
        "            _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "            loss_val = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss_val += loss_val.item()\n",
        "            running_corrects_val += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "        test_data_len = len(testloader.dataset)\n",
        "        epoch_loss = running_loss_val / test_data_len\n",
        "        epoch_acc = running_corrects_val.double() / test_data_len\n",
        "\n",
        "        loss_plot_val.append(epoch_loss)\n",
        "        accuracy_plot_val.append(epoch_acc)\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "        # print(loss)\n",
        "    torch.save(resnet18.state_dict(), 'resnet18_FC_Only.pth')\n",
        "\n",
        "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "fOOsNR1eSaEZ",
        "colab_type": "text"
      },
      "source": [
        "### Plot Loss & Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Mlte84yNSaEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot,label=\"Training Accuracy\")\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot_val,label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),loss_plot,label=\"Training Loss\")\n",
        "plt.plot(range(1,Epochs+1),loss_plot_val,label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LbI-Xn0nSaEd",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix & Two Worse and Best Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oEWonpMBSaEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "number_of_classes = 2\n",
        "confusion_matrix = torch.zeros(number_of_classes, number_of_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        outputs = resnet18(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(label.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "zOo9dGZ5SaEg",
        "colab_type": "text"
      },
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2zrUo3XWSaEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,(inputs,label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        # compute output\n",
        "        output = resnet18(inputs)\n",
        "        loss = criterion(output,label)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        # losses.update(loss.item(),input.size(0))\n",
        "        f1_batch = f1_score(label.cpu(),preds.cpu() > 0.15,average='macro')\n",
        "print('F1 Score: ',f1_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "HpqmYlGzSaEn",
        "colab_type": "text"
      },
      "source": [
        "### Final Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sDk0l2z_SaEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader) # converted it to train because test batch is of 1500 (converted to increase speed)\n",
        "images, labels = dataiter.next()\n",
        "show_databatch(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "W5f5df4VSaEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
        "outputs = resnet18(images)                               #--> forward pass\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
        "                              for j in range(len(images))))\n",
        "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
        "                              for j in range(len(images))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UtadS-ENSaE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet18(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Final Accuracy of the network on the 1500 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-d484eJnljL",
        "colab_type": "text"
      },
      "source": [
        "### Best and Worse Performing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "08zh_LrlSaE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "best_performing_image1 = 0\n",
        "best_performing_image2 = 0\n",
        "best_performing_image1_label = \"\"\n",
        "best_performing_image2_label = \"\"\n",
        "\n",
        "worse_performing_image1 = 0\n",
        "worse_performing_image2 = 0\n",
        "worse_performing_image1_label = \"\"\n",
        "worse_performing_image2_label = \"\"\n",
        "\n",
        "maximum = 0\n",
        "minimum = -9999\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet18(images)\n",
        "        probabilities, predicted = torch.max(outputs.data,1)\n",
        "\n",
        "        T_Pred_Mask= probabilities[predicted==labels]\n",
        "        F_Pred_Mask= probabilities[predicted!=labels]\n",
        "\n",
        "        if any(T_Pred_Mask) == True:\n",
        "          temp_max = torch.argmax(probabilities[predicted==labels])\n",
        "          if maximum < temp_max:\n",
        "            maximum = temp_max\n",
        "            best_performing_image2 = best_performing_image1\n",
        "            best_performing_image2_label = best_performing_image1_label\n",
        "\n",
        "            best_performing_image1_label = labels[maximum]\n",
        "            best_performing_image1 = images[maximum]\n",
        "        \n",
        "        if any(F_Pred_Mask) == True:\n",
        "          temp_min = torch.argmin(probabilities[predicted!=labels])\n",
        "          if minimum > temp_min  :\n",
        "            minimum = temp_min\n",
        "            worse_performing_image2 = worse_performing_image1\n",
        "            worse_performing_image2_label = worse_performing_image1_label\n",
        "\n",
        "            worse_performing_image1_label = labels[minimum]\n",
        "            worse_performing_image1 = images[minimum]\n",
        "\n",
        "        # total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "print('True Positive or True Negative with High Probability')\n",
        "imshow(best_performing_image1.cpu(),best_performing_image1_label.cpu())\n",
        "imshow(best_performing_image2.cpu(),best_performing_image2_label.cpu())\n",
        "\n",
        "print('False Positive or False Negative with High Probability')\n",
        "imshow(worse_performing_image1.cpu(),worse_performing_image1_label.cpu())\n",
        "imshow(worse_performing_image2.cpu(),worse_performing_image2_label.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tmuo4vRySaE5",
        "colab_type": "text"
      },
      "source": [
        "## VGG-16\n",
        "### Fine-tuning vgg16 on X-Ray Chest data\n",
        "In this tutorial we will learn how to fine-tune a pre-trained network on a new dataset.\n",
        "We will perform the following steps:\n",
        "1. Load and normalizing the X-Ray dataset\n",
        "2. Load pre-trained Vgg16 \n",
        "3. Remove top layers (fully connected layers)\n",
        "4. Freeze the network\n",
        "4. Add new layers (classifier)\n",
        "5. Train the network\n",
        "6. Plot Loss & Accuracies with Epochs\n",
        "7. Confusion Matrix\n",
        "8. F1 Score\n",
        "9. Test Final Accuracy on test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JP0lFG65SaE5",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r4X2OLxqSaE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the pretrained model from pytorch\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "print(vgg16)\n",
        "print('Output Layer of VGG16 : ', vgg16.classifier[6].out_features) # 1000 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oxbs53UDSaE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vgg16.classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "19Rx1NPKSaE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = vgg16.classifier[0].in_features # 0 means input we are receiving from VGG Conv features\n",
        "# putting array value 0 instead of -1 (which is used to neglect last layer) to add new layers\n",
        "features = list(vgg16.classifier.children())[:0] # Remove all FC layer\n",
        "print(num_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "s8TmW3IdSaFD",
        "colab_type": "text"
      },
      "source": [
        "### Freezing the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1s-kq2egSaFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze training for all layers\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for i in range(0,31): # Unfreezing all CNN Layer\n",
        "  vgg16.features[i].requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-_giKMRESaFJ",
        "colab_type": "text"
      },
      "source": [
        "### Adding New Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2QKyaEQ5SaFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roll_number_neurons = 22*10+100\n",
        "features.extend([\n",
        "                 nn.Linear(num_features, roll_number_neurons)\n",
        "                 ,nn.ReLU(inplace=True)\n",
        "                 ,nn.Linear(roll_number_neurons, len(class_names))\n",
        "                 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Zak0qgGASaFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16.classifier = nn.Sequential(*features)\n",
        "print(vgg16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7cgbMwf4SaFP",
        "colab_type": "text"
      },
      "source": [
        "### Loss fucntion and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QN9XdQ2ySaFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epochs = 3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "c3xdt6amSaFS",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-vt4YqXNSaFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "since = time.time()\n",
        "#if you have gpu then you need to convert the network and data to cuda\n",
        "#the easiest way is to first check for device and then convert network and data to device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "vgg16.to(device)\n",
        "\n",
        "# vgg16.train()\n",
        "loss_plot = []\n",
        "loss_plot_val = []\n",
        "accuracy_plot = []\n",
        "accuracy_plot_val=[]\n",
        "\n",
        "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    epoch_loss=0.0\n",
        "    epoch_acc=0\n",
        "    pbar = tqdm(enumerate(trainloader))\n",
        "    for i, data in pbar:\n",
        "        # if i==20: #my code was failing due to CUDA memory, so doing this to train on subset\n",
        "        #   break\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
        "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "        # This is convenient while training RNNs. \n",
        "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = vgg16(inputs)               #----> forward pass\n",
        "        _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "        loss = criterion(outputs, labels)   #----> compute loss\n",
        "        \n",
        "        loss.backward()                     #----> backward pass\n",
        "        optimizer.step()                    #----> weights update\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        train_data_len = len(trainloader.dataset)\n",
        "        epoch_loss = running_loss / train_data_len\n",
        "        epoch_acc = running_corrects.double() / train_data_len\n",
        "\n",
        "        pbar.set_description(\n",
        "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tTraining Loss: {:.4f}  Training Acc: {:.4f}'.format(\n",
        "                epoch, i * len(inputs), len(trainloader.dataset),\n",
        "                100. * i / len(trainloader),\n",
        "                epoch_loss, epoch_acc))\n",
        "        # pbar.set_description(\n",
        "        #     'Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc)\n",
        "        #     )\n",
        "    \n",
        "    \n",
        "\n",
        "    loss_plot.append(epoch_loss)\n",
        "    \n",
        "    accuracy_plot.append(epoch_acc)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        running_loss_val = 0.0\n",
        "        running_corrects_val=0.0\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = vgg16(images)               #----> forward pass\n",
        "            _, preds = torch.max(outputs, 1) #added line for accuracy\n",
        "            loss_val = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss_val += loss_val.item()\n",
        "            running_corrects_val += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "        test_data_len = len(testloader.dataset)\n",
        "        epoch_loss = running_loss_val / test_data_len\n",
        "        epoch_acc = running_corrects_val.double() / test_data_len\n",
        "\n",
        "        loss_plot_val.append(epoch_loss)\n",
        "        accuracy_plot_val.append(epoch_acc)\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "        # print(loss)\n",
        "    torch.save(vgg16.state_dict(), 'vgg16_FC_Only.pth')\n",
        "\n",
        "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rs50Cv_VSaFU",
        "colab_type": "text"
      },
      "source": [
        "### Plot Loss & Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZCqfp4aNSaFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot,label=\"Training Accuracy\")\n",
        "plt.plot(range(1,Epochs+1),accuracy_plot_val,label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.xticks(np.arange(1, Epochs+1, 1.0))\n",
        "plt.plot(range(1,Epochs+1),loss_plot,label=\"Training Loss\")\n",
        "plt.plot(range(1,Epochs+1),loss_plot_val,label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tpGODpKzSaFb",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix & Two Worse and Best Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ECyQNnEASaFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "number_of_classes = 2\n",
        "confusion_matrix = torch.zeros(number_of_classes, number_of_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        outputs = vgg16(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(label.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "O_Ka_n85SaFe",
        "colab_type": "text"
      },
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "b7yFUAcsSaFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,(inputs,label) in enumerate(testloader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "        # compute output\n",
        "        output = vgg16(inputs)\n",
        "        loss = criterion(output,label)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        # losses.update(loss.item(),input.size(0))\n",
        "        f1_batch = f1_score(label.cpu(),preds.cpu() > 0.15,average='macro')\n",
        "print('F1 Score: ',f1_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WZQO5KLgSaFg",
        "colab_type": "text"
      },
      "source": [
        "### Final Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ao80XWaJSaFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader) # converted it to train because test batch is of 1500 (converted to increase speed)\n",
        "images, labels = dataiter.next()\n",
        "show_databatch(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MSyPYuA3SaFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = images.to(device), labels.to(device) #-->convert test image to cuda (if available)\n",
        "outputs = vgg16(images)                               #--> forward pass\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % class_names[predicted[j]]\n",
        "                              for j in range(len(images))))\n",
        "print('Ground Truth: ', ' '.join('%5s' % class_names[labels[j]]\n",
        "                              for j in range(len(images))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iv5XBhpzSaFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = vgg16(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Final Accuracy of the network on the 1500 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI8kmNvcnuTM",
        "colab_type": "text"
      },
      "source": [
        "### Best and Worse Performing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TBkgGfpsSaFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "best_performing_image1 = 0\n",
        "best_performing_image2 = 0\n",
        "best_performing_image1_label = \"\"\n",
        "best_performing_image2_label = \"\"\n",
        "\n",
        "worse_performing_image1 = 0\n",
        "worse_performing_image2 = 0\n",
        "worse_performing_image1_label = \"\"\n",
        "worse_performing_image2_label = \"\"\n",
        "\n",
        "maximum = 0\n",
        "minimum = -9999\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet18(images)\n",
        "        probabilities, predicted = torch.max(outputs.data,1)\n",
        "\n",
        "        T_Pred_Mask= probabilities[predicted==labels]\n",
        "        F_Pred_Mask= probabilities[predicted!=labels]\n",
        "\n",
        "        if any(T_Pred_Mask) == True:\n",
        "          temp_max = torch.argmax(probabilities[predicted==labels])\n",
        "          if maximum < temp_max:\n",
        "            maximum = temp_max\n",
        "            best_performing_image2 = best_performing_image1\n",
        "            best_performing_image2_label = best_performing_image1_label\n",
        "\n",
        "            best_performing_image1_label = labels[maximum]\n",
        "            best_performing_image1 = images[maximum]\n",
        "        \n",
        "        if any(F_Pred_Mask) == True:\n",
        "          temp_min = torch.argmin(probabilities[predicted!=labels])\n",
        "          if minimum > temp_min  :\n",
        "            minimum = temp_min\n",
        "            worse_performing_image2 = worse_performing_image1\n",
        "            worse_performing_image2_label = worse_performing_image1_label\n",
        "\n",
        "            worse_performing_image1_label = labels[minimum]\n",
        "            worse_performing_image1 = images[minimum]\n",
        "\n",
        "        # total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "print('True Positive or True Negative with High Probability')\n",
        "imshow(best_performing_image1.cpu(),best_performing_image1_label.cpu())\n",
        "imshow(best_performing_image2.cpu(),best_performing_image2_label.cpu())\n",
        "\n",
        "print('False Positive or False Negative with High Probability')\n",
        "imshow(worse_performing_image1.cpu(),worse_performing_image1_label.cpu())\n",
        "imshow(worse_performing_image2.cpu(),worse_performing_image2_label.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2-7KH1VdSaFv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}